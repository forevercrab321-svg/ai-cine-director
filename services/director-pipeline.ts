import {
  generateImage,
  startVideoTask,
  checkPredictionStatus,
} from "./replicateService";
import { supabase } from '../lib/supabaseClient';
import type {
  VideoModel,
  VideoStyle,
  GenerationMode,
  VideoQuality,
  VideoDuration,
  VideoFps,
  VideoResolution,
} from "../types";

/**
 * â˜… SERVER-SIDE FRAME EXTRACTION â€” Replaces browser canvas approach
 * The browser canvas method fails with CORS SecurityError on replicate.delivery URLs.
 * This calls the backend API which downloads the video server-side (no CORS) and
 * runs ffmpeg to extract the last frame as Base64 JPEG.
 */
async function extractLastFrameServerSide(videoUrl: string): Promise<string> {
  const { data: { session } } = await supabase.auth.getSession();
  if (!session) throw new Error("Not authenticated");

  console.log(`ğŸ“¸ [FrameExtract] Calling server-side frame extractor...`);

  const response = await fetch('/api/extract-frame', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${session.access_token}`
    },
    body: JSON.stringify({ videoUrl })
  });

  if (!response.ok) {
    const errText = await response.text();
    throw new Error(`Frame extraction failed (${response.status}): ${errText}`);
  }

  const data = await response.json();
  if (!data.frame) {
    throw new Error('Frame extraction returned no frame data');
  }

  if (data.fallback) {
    console.warn(`âš ï¸ [FrameExtract] ffmpeg unavailable, using raw URL fallback â€” backend will convert to Base64`);
  } else {
    console.log(`âœ… [FrameExtract] Server-side frame extraction success`);
  }

  return data.frame;
}


export interface StoryboardShot {
  image_prompt: string;
  video_prompt: string;
  transition?: "hard_cut" | "seamless";
}

const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));

/**
 * è½®è¯¢ç­‰å¾…è§†é¢‘ç”Ÿæˆå®Œæˆå¹¶è·å–æœ€ç»ˆè§†é¢‘ URL
 * @param predictionId æ¨¡å‹ç”Ÿæˆä»»åŠ¡çš„ ID
 */
async function waitForVideoCompletion(predictionId: string): Promise<string> {
  while (true) {
    await sleep(3000); // è½®è¯¢é—´éš”ï¼š3ç§’
    const prediction = await checkPredictionStatus(predictionId);

    if (prediction.status === "succeeded") {
      const output = prediction.output;
      // Replicate çš„è¾“å‡ºå¯èƒ½æ˜¯ä¸€ä¸ªæ•°ç»„æˆ–å­—ç¬¦ä¸²ï¼Œè¿™é‡Œæå–é¦–ä¸ª URL
      return typeof output === "string" ? output : output[0];
    }

    if (prediction.status === "failed" || prediction.status === "canceled") {
      throw new Error(
        `Video generation failed: ${prediction.error || "Task canceled"}`,
      );
    }
  }
}

/**
 * è¿è¡Œâ€œå¯¼æ¼”æ¨¡å¼â€çš„æ— ç¼ä¸²è”ç”Ÿæˆå·¥ä½œæµã€‚
 * æ‰§è¡Œé€»è¾‘ï¼š
 * 1. éå†é•œå¤´ï¼Œç¬¬ä¸€é•œé€šè¿‡æ–‡æœ¬ç”Ÿæˆé¦–å¸§å›¾åƒã€‚
 * 2. åç»­é•œå¤´ç›´æ¥å¤ç”¨ä¸Šä¸€é•œæœ€åæŠ½å–çš„ç”»é¢ (Base64) ä½œä¸ºè¿™é•œçš„é¦–å¸§ã€‚
 * 3. å¹¶å‘é€ä¸ºè§†é¢‘ã€‚
 * 4. éæœ€ç»ˆé•œï¼ŒæŠ½å–æœ€ç»ˆè§†é¢‘ç”»é¢çš„æœ€åä¸€å¸§ï¼Œä¾›ä¸‹ä¸€æ¬¡è¿­ä»£ä½¿ç”¨ã€‚
 *
 * @param storyboard æ•…äº‹æ¿é•œå¤´æ•°ç»„ï¼ŒåŒ…å« image_prompt å’Œ video_prompt
 * @param characterAnchor è§’è‰²ç‰¹å¾é”šç‚¹
 * @returns åŒ…å«æ‰€æœ‰ç”Ÿæˆçš„è¿ç»­è§†é¢‘ URL æ•°ç»„
 */
export const generateSceneChain = async (
  sceneId: string,
  storyboard: any[],
  extractedAnchor: string,
  onProgress?: (data: {
    index: number;
    stage: string;
    imageUrl?: string;
    videoUrl?: string;
    predictionId?: string;
  }) => void
) => {
  let previousVideoLastFrame: string | null = null;
  const videoUrls: string[] = [];

  for (let i = 0; i < storyboard.length; i++) {
    const shot = storyboard[i];
    let currentStartImage: string;

    console.log(`\nğŸ¬ --- å¼€å§‹åˆ¶ä½œç¬¬ ${i + 1} é•œ ---`);
    if (i === 0) {
      console.log("ğŸš€ [ç¬¬ä¸€é•œ] å¼ºåˆ¶ä½¿ç”¨ Flux å¼•æ“ç”Ÿæˆåˆå§‹èµ·æ­¥å›¾...");
      const imgPrompt = shot.image_prompt || shot.visual_description || `Cinematic shot, Scene ${i + 1}`;
      currentStartImage = await generateImage(
        imgPrompt,
        "flux_schnell",
        "none",
        "16:9",
        extractedAnchor
      );
      if (onProgress) {
        onProgress({ index: i, stage: "image_done", imageUrl: currentStartImage });
      }
    } else {
      console.log(`ğŸš€ [ç¬¬ ${i + 1} é•œ] å¼ºåˆ¶æ‹¦æˆªï¼æ‹’ç»é‡æ–°ç”Ÿå›¾ï¼Œç›´æ¥è¯»å–ä¸Šä¸€é•œçš„å°¾å¸§ä½œä¸ºèµ·æ­¥å›¾ï¼`);
      if (!previousVideoLastFrame) {
        console.error("âŒ ä¸¥é‡é”™è¯¯ï¼šå°¾å¸§æ¥åŠ›æ£’ä¸¢å¤±ï¼");
        throw new Error("æ— æ³•è·å–ä¸Šä¸€é•œå¤´çš„å°¾å¸§ï¼Œè¿ç»­ç”Ÿæˆè¢«è¿«ç»ˆæ­¢ã€‚");
      }
      // ã€å¼ºåˆ¶å†™æ­»ã€‘ï¼šç»å¯¹ä¸å…è®¸åœ¨ i > 0 æ—¶è°ƒç”¨ generateImageã€‚å¿…é¡»ä½¿ç”¨ Base64 å°¾å¸§ã€‚
      currentStartImage = previousVideoLastFrame;
      if (onProgress) {
        onProgress({ index: i, stage: "image_done", imageUrl: currentStartImage });
      }
    }

    console.log(`ğŸ¥ [é˜¶æ®µ 2] å‘é€è§†é¢‘ç”Ÿæˆè¯·æ±‚: ${shot.video_prompt}`);
    if (onProgress) {
      onProgress({ index: i, stage: "video_starting" });
    }

    // â˜… åŒé‡æ­»é”ï¼š1)è§†è§‰é”(å°¾å¸§å›¾ç‰‡) 2)æ–‡å­—é”(è§’è‰²é”šç‚¹æ³¨å…¥ prompt)
    // ä¸å…è®¸åªå‘åŠ¨ä½œæè¿°ï¼é”šç‚¹å¿…é¡»ç„Šå…¥æ¯ä¸€é•œçš„ promptï¼Œé˜²æ­¢å¤§æ¨¡å‹è§’è‰²å¹»è§‰
    const rawVideoPrompt = shot.video_prompt || shot.video_motion_prompt || `Cinematic motion, scene ${i + 1}`;
    const lockedVideoPrompt = extractedAnchor
      ? `${rawVideoPrompt}. IDENTITY LOCK: ${extractedAnchor}.`
      : rawVideoPrompt;

    console.log(`ğŸ”’ [Shot ${i + 1}] Locked prompt: ${lockedVideoPrompt.slice(0, 120)}...`);

    // æ³¨æ„ï¼šè¿™é‡Œæ‰€æœ‰çš„è§†é¢‘éƒ½ç»Ÿä¸€é”å®šåŒä¸€ä¸ªæ¨¡å‹ï¼ˆä¾‹å¦‚ hailuo_02_fastï¼‰ï¼Œä¿è¯è¿åŠ¨ç‰©ç†å¼•æ“ä¸€è‡´
    const videoPrediction = await startVideoTask(
      lockedVideoPrompt,
      currentStartImage,
      "hailuo_02_fast" as VideoModel,
      "none" as VideoStyle,
      "storyboard" as GenerationMode,
      "standard" as VideoQuality,
      "6s" as unknown as VideoDuration,
      "24fps" as unknown as VideoFps,
      "720p" as VideoResolution,
      extractedAnchor,   // Still passed here so buildVideoInput can also append it
      "16:9"
    );

    if (onProgress) {
      onProgress({ index: i, stage: "video_polling", predictionId: videoPrediction.id });
    }

    // è¿™é‡Œ startVideoTask åªè¿”å›äº†ä»»åŠ¡çš„çŠ¶æ€ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦è½®è¯¢æŸ¥è¯¢è·å¾—æœ€ç»ˆè§†é¢‘ URL
    const generatedVideoUrl = await waitForVideoCompletion(videoPrediction.id);
    videoUrls.push(generatedVideoUrl);
    console.log(`âœ… [ç¬¬ ${i + 1} é•œ] è§†é¢‘ç”ŸæˆæˆåŠŸ: ${generatedVideoUrl}`);

    if (onProgress) {
      onProgress({ index: i, stage: "video_done", videoUrl: generatedVideoUrl });
    }

    // ã€å¼ºåˆ¶å†™æ­»ã€‘ï¼šåªè¦å½“å‰ä¸æ˜¯æœ€åä¸€ä¸ªé•œå¤´ï¼Œæ­»ç­‰æˆªå¸§å®Œæˆï¼
    if (i < storyboard.length - 1) {
      console.log(`ğŸ“¸ [Shot ${i + 1}] æ­£åœ¨è°ƒç”¨æœåŠ¡ç«¯æˆªå¸§ï¼ˆç»•è¿‡ CORSï¼‰...`);
      try {
        previousVideoLastFrame = await extractLastFrameServerSide(generatedVideoUrl);
        const frameType = previousVideoLastFrame.startsWith('data:') ? 'Base64' : 'URL';
        console.log(`âœ… [Shot ${i + 1}] å°¾å¸§æˆªå–æˆåŠŸ (${frameType})ï¼ŒBase64 é•¿åº¦: ${previousVideoLastFrame.length}`);
        console.log(`[Chain Check] Shot ${i + 2} will use tail frame: ${frameType}, size=${previousVideoLastFrame.length}, hasData=${previousVideoLastFrame.length > 100}`);
      } catch (frameErr: any) {
        console.error(`âŒ [Shot ${i + 1}] å°¾å¸§æˆªå–å¤±è´¥ï¼é”™è¯¯: ${frameErr.message}`);
        console.error(`âŒ é”é“¾å°†åœ¨ç¬¬ ${i + 2} é•œæ–­è£‚ â€” ä¸­æ­¢æ‰§è¡Œã€‚`);
        throw frameErr; // Propagate up â€” do NOT let chain continue silently
      }
    }
  }

  console.log("ğŸ‰ å…¨éƒ¨é”é“¾ç”Ÿæˆå®Œæ¯•ï¼ŒçœŸæ­£çš„ä¸€é•œåˆ°åº•ï¼");
  return videoUrls;
};
